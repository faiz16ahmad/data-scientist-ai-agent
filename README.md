# ğŸ¤– Data Scientist AI Agent

An intelligent and collaborative Data Scientist AI Agent powered by Google Gemini that transforms natural language queries into comprehensive data analysis and interactive visualizations.

## âœ¨ Key Features

### ğŸ§  **Intelligent Analysis**
- **Natural Language Processing**: Ask complex questions about your data in plain English
- **5-Step Reasoning Process**: Grounding â†’ Planning â†’ Execution â†’ Critique â†’ Delivery
- **Interactive Clarification**: Agent asks for clarification when queries are ambiguous
- **Fuzzy Column Matching**: Intelligent column name resolution and suggestions

### ğŸ“Š **Advanced Visualizations**
- **Interactive Plotly Charts**: Bar, line, scatter, histogram, box plots, and more
- **Complex Visualizations**: Sunburst, treemaps, 3D plots, correlation matrices
- **Real-time Rendering**: Seamless integration with Streamlit interface
- **Export Capabilities**: Save charts and analysis results

### ğŸ”¬ **Machine Learning & Statistics**
- **Advanced Analytics**: Statistical summaries, correlations, trend analysis
- **ML Models**: XGBoost, clustering, predictions, feature importance
- **Model Explainability**: SHAP values, LIME explanations
- **Time Series Analysis**: Forecasting with Prophet and ARIMA

### ğŸ›¡ï¸ **Production-Ready Features**
- **Secure Code Execution**: Sandboxed Python environment with persistent variables
- **Rate Limiting**: Intelligent API usage management (8-12 requests/min)
- **Error Handling**: Graceful degradation and comprehensive error recovery
- **Comprehensive Testing**: 50-question automated test suite

### ğŸ§ª **Testing & Quality Assurance**
- **Automated Test Suite**: 50 carefully crafted questions across 5 categories
- **Performance Metrics**: 4-criteria evaluation system with 75% pass threshold
- **Real-time Monitoring**: Streamlit dashboard for test execution and results
- **Category Analysis**: Data understanding, visualization, statistical analysis

## ğŸ”§ Prerequisites

- **Python 3.9+**
- **Google Gemini API key** ([Get yours here](https://makersuite.google.com/app/apikey))
- **(Optional)** LangSmith API key for observability and debugging

## ğŸš€ Quick Start

### Method 1: Automated Setup (Recommended)

1. **Clone and setup**:
   ```bash
   git clone <your-repo-url>
   cd windsurf-project
   python setup.py
   ```

2. **Configure API key**:
   ```bash
   cp .env.example .env
   # Edit .env and add your Google Gemini API key
   ```

3. **Launch the application**:
   ```bash
   # Windows:
   run_venv.bat
   
   # Unix/Linux/macOS:
   ./run_venv.sh
   ```

### Method 2: Manual Setup

1. **Create virtual environment**:
   ```bash
   python -m venv venv
   
   # Activate environment
   # Windows:
   venv\Scripts\activate
   # Unix/Linux/macOS:
   source venv/bin/activate
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**:
   ```bash
   # Create .env file
   echo "GOOGLE_API_KEY=your_api_key_here" > .env
   ```

4. **Run the application**:
   ```bash
   streamlit run src/app.py
   ```

### ğŸ”‘ API Key Setup

1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Click "Create API Key" 
3. Copy your API key
4. Add to `.env` file: `GOOGLE_API_KEY=your_key_here`

> **Security Note**: Never commit your `.env` file to version control

## ğŸ’» Usage

### ğŸŒ **Web Interface**

1. **Upload your data**: Support for CSV and Excel files
2. **Ask questions**: Use natural language queries like:
   - "Show me a bar chart of sales by region"
   - "What's the correlation between price and sales?"
   - "Create a scatter plot with trend line"
   - "Predict next month's revenue using machine learning"

3. **Interactive analysis**: The agent will clarify ambiguous requests and provide step-by-step analysis

### ğŸ“ **Example Queries**

```
ğŸ“Š Visualization:
â€¢ "Create a histogram of customer ages"
â€¢ "Show sales trends over time with a line chart"
â€¢ "Make a correlation heatmap of all numeric columns"

ğŸ” Analysis:
â€¢ "What are the top 5 products by revenue?"
â€¢ "Calculate the average order value by customer segment"
â€¢ "Find outliers in the pricing data"

ğŸ¤– Machine Learning:
â€¢ "Build a model to predict customer churn"
â€¢ "Cluster customers based on their behavior"
â€¢ "Show feature importance for sales prediction"
```

### ğŸ§ª **Testing Your Agent**

Run the comprehensive test suite to evaluate performance:

```bash
# Quick test (10 questions)
python run_tests.py

# Full test suite (50 questions)
# Select option 2 when prompted

# Interactive testing dashboard
streamlit run src/testing/test_app.py
```

**Test Categories:**
- Data Understanding (10 questions)
- Basic Visualization (10 questions) 
- Advanced Analysis (10 questions)
- Complex Visualization (10 questions)
- Statistical Analysis (10 questions)

The application opens at `http://localhost:8501`

## ğŸ“ Project Structure

```
windsurf-project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                    # ğŸŒ Main Streamlit application
â”‚   â”œâ”€â”€ agent.py                  # ğŸ¤– ReAct agent with 5-step reasoning
â”‚   â”œâ”€â”€ utils.py                  # ğŸ› ï¸ Data processing & visualization utilities
â”‚   â”œâ”€â”€ query_analyzer/           # ğŸ§  Query analysis & clarification system
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py              # Query analysis logic
â”‚   â”‚   â”œâ”€â”€ prompts.py           # LLM prompt templates
â”‚   â”‚   â””â”€â”€ schemas.py           # Pydantic data models
â”‚   â””â”€â”€ testing/                  # ğŸ§ª Comprehensive test suite
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ test_questions.py    # 50 test questions bank
â”‚       â”œâ”€â”€ test_runner.py       # Automated test execution
â”‚       â”œâ”€â”€ results_analyzer.py  # Results analysis & visualization
â”‚       â””â”€â”€ test_app.py         # Streamlit testing dashboard
â”œâ”€â”€ docs/                        # ğŸ“š Documentation files
â”‚   â”œâ”€â”€ SETUP_GUIDE.md          # Detailed setup instructions
â”‚   â”œâ”€â”€ TESTING_README.md       # Testing framework guide
â”‚   â””â”€â”€ RATE_LIMITING_GUIDE.md  # API usage management
â”œâ”€â”€ run_tests.py                 # ğŸš€ Quick test runner
â”œâ”€â”€ setup.py                     # ğŸ”§ Automated setup script
â”œâ”€â”€ .env.example                 # ğŸ” Environment variables template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt             # ğŸ“¦ Python dependencies
```

## ğŸ—ï¸ Architecture

### Core Components

1. **Streamlit Frontend** (`app.py`): Interactive web interface with file upload and chat
2. **ReAct Agent** (`agent.py`): LangChain-powered agent with 5-step reasoning process
3. **Query Analyzer** (`query_analyzer/`): Intent classification and clarification system
4. **Testing Suite** (`testing/`): Automated evaluation with 50 diverse questions
5. **Utilities** (`utils.py`): Data processing and Plotly visualization helpers

### Agent Workflow

```mermaid
graph TD
    A[User Query] --> B[Grounding & Verification]
    B --> C[Query Analysis & Planning]
    C --> D[Step-by-Step Execution]
    D --> E[Self-Critique & Refinement]
    E --> F[Final Answer Delivery]
    F --> G[Interactive Visualization]
```

## ğŸ”§ Advanced Configuration

### Rate Limiting
```python
# Adjust API rate limits (default: 8 requests/min)
runner = TestRunner(df, rate_limit_requests=10)
```

### Custom Agent Settings
```python
# Modify agent behavior in agent.py
agent = DataScientistAgent(df)
agent.llm.temperature = 0.2  # Adjust creativity
```

### Environment Variables
```bash
# .env file configuration
GOOGLE_API_KEY=your_api_key_here
LANGCHAIN_API_KEY=your_langsmith_key  # Optional
LANGCHAIN_TRACING_V2=true            # Optional
DEBUG=True                           # Enable debug mode
```

## ğŸš¨ Troubleshooting

### Common Issues

**API Key Errors:**
```bash
# Verify API key is set
python -c "import os; from dotenv import load_dotenv; load_dotenv(); print('âœ… API Key found!' if os.getenv('GOOGLE_API_KEY') else 'âŒ API Key missing!')"
```

**Rate Limiting:**
- Reduce concurrent requests in test runner
- Use conservative rate limits (5-8 requests/min)
- Check for other API usage

**Memory Issues:**
```python
# Sample large datasets
df_sample = df.sample(n=1000)
```

**Import Errors:**
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

## ğŸ“Š Performance Benchmarks

| Test Category | Target Pass Rate | Avg Execution Time |
|---------------|------------------|-------------------|
| Data Understanding | >90% | <5s |
| Basic Visualization | >85% | <8s |
| Advanced Analysis | >75% | <12s |
| Complex Visualization | >70% | <15s |
| Statistical Analysis | >65% | <20s |

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Run tests (`python run_tests.py`)
4. Commit changes (`git commit -m 'Add amazing feature'`)
5. Push to branch (`git push origin feature/amazing-feature`)
6. Open a Pull Request

### Development Setup
```bash
# Install development dependencies
pip install -r requirements.txt
pip install pytest black flake8

# Run code formatting
black src/
flake8 src/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **AI/ML Stack**: [LangChain](https://python.langchain.com/) + [Google Gemini](https://ai.google.dev/)
- **Frontend**: [Streamlit](https://streamlit.io/) for rapid prototyping
- **Visualization**: [Plotly](https://plotly.com/) for interactive charts
- **Data Science**: [Pandas](https://pandas.pydata.org/), [Scikit-learn](https://scikit-learn.org/), [XGBoost](https://xgboost.readthedocs.io/)

## ğŸ”— Related Documentation

- [ğŸ“š Setup Guide](docs/SETUP_GUIDE.md) - Detailed installation instructions
- [ğŸ§ª Testing Guide](docs/TESTING_README.md) - Comprehensive testing framework
- [ğŸš¦ Rate Limiting](docs/RATE_LIMITING_GUIDE.md) - API usage management

---

**Ready to transform your data analysis workflow with AI?** ğŸš€ğŸ“ŠğŸ¤–
